{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from networks.LUTDeiT import LUT_DeiT, LUT_Distilled_DeiT, Attention2, create_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm import create_model\n",
    "from operations.amm_linear import LUT_Linear\n",
    "from qat.export.utils import replace_module_by_name, fetch_module_by_name\n",
    "from torchinfo import summary\n",
    "from thop import profile, clever_format\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch_tensorrt\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "def benchmark(model, input_shape=(1024, 3, 512, 512), dtype='fp32', nwarmup=50, nruns=1000, cuda=False):\n",
    "    input_data = torch.randn(input_shape)\n",
    "    if cuda:\n",
    "        input_data = input_data.to(\"cuda\")\n",
    "    if dtype=='fp16':\n",
    "        input_data = input_data.half()\n",
    "        \n",
    "    print(\"Warm up ...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(nwarmup):\n",
    "            features = model(input_data)\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Start timing ...\")\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(1, nruns+1):\n",
    "            start_time = time.time()\n",
    "            pred_loc  = model(input_data)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            timings.append(end_time - start_time)\n",
    "            if i%10==0:\n",
    "                print('Iteration %d/%d, avg batch time %.2f ms'%(i, nruns, np.mean(timings)*1000))\n",
    "\n",
    "    print(\"Input shape:\", input_data.size())\n",
    "    print('Average throughput: %.2f images/second'%(input_shape[0]/np.mean(timings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'resmlp_12_224.fb_in1k'\n",
    "model_name = 'deit3_small_patch16_224.fb_in22k_ft_in1k'\n",
    "\n",
    "model = create_model(model_name=model_name, pretrained=False)\n",
    "model.eval()\n",
    "subvec_len =32\n",
    "ncodebooks = {\n",
    "        \"attn.qkv\": 384 // subvec_len,\n",
    "        # \"attn.q_linear\": 384 // subvec_len, \n",
    "        # \"attn.k_linear\": 384 // subvec_len, \n",
    "        \"mlp.fc1\": 384 // subvec_len\n",
    "        # \"mlp.fc2\": 1536 // subvec_len\n",
    "        \n",
    "        # \"linear_tokens\": 196 // 14, \n",
    "        # \"mlp_channels.fc1\": 384 // subvec_len,\n",
    "        # \"mlp_channels.fc2\":1536 // subvec_len\n",
    "    }\n",
    "for i in range(0, 12): \n",
    "    for name in ncodebooks:\n",
    "        layer = model.blocks[i]\n",
    "        module = fetch_module_by_name(layer, name)\n",
    "        amm_linear = LUT_Linear(\n",
    "        # amm_linear = PQLinear(\n",
    "            ncodebooks[name],\n",
    "            module.in_features,\n",
    "            module.out_features,\n",
    "            module.bias is not None,\n",
    "            k=16\n",
    "        )\n",
    "        # print(amm_linear.weight.data.shape)\n",
    "        # print(module.weight.data.shape)\n",
    "        # weight = rearrange(module.weight.data, 'o i -> i o')\n",
    "        # weight = rearrange(weight, '(c v) o -> c v o', c=ncodebooks[name], v=subvec_len)\n",
    "        # amm_linear.weight.data.copy_(weight.data)\n",
    "        # amm_linear.bias.data.copy_(module.bias.data)\n",
    "        replace_module_by_name(layer, name, amm_linear)\n",
    "model_compressed = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_lut_linear(module: nn.Module, input: torch.Tensor, output: torch.Tensor):\n",
    "    # 计算参数\n",
    "    # n_params = module.ncodebooks * module.k * module.subvec_len  # centroids\n",
    "    # n_params += module.ncodebooks * module.k * module.out_features/(32/8)  # luts \n",
    "    # if module.bias is not None:\n",
    "    #     n_params += module.out_features  # bias\n",
    "    # module.total_params[0] = torch.DoubleTensor([n_params])\n",
    "    n_mults = module.ncodebooks * input[0].shape[0] * module.k * module.subvec_len\n",
    "    n_adds = module.ncodebooks * input[0].shape[0] * module.k * (module.subvec_len - 1)\n",
    "    n_lut_adds = module.ncodebooks * input[0].shape[0] * module.out_features\n",
    "    if module.bias is not None:\n",
    "        n_adds += input[0].shape[0] * module.out_features\n",
    "    module.total_ops += torch.DoubleTensor([n_mults + n_adds + n_lut_adds])\n",
    "\n",
    "custom_ops = {LUT_Linear: count_lut_linear}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 3, 224, 224).cuda()\n",
    "flops, params = profile(model_compressed.cuda(), inputs=(input, ), custom_ops=custom_ops)\n",
    "flops, params = clever_format([flops, params], \"%.3f\")\n",
    "print(f\"FLOPS: {flops}, Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(model_name=model_name, pretrained=True)\n",
    "flops, params = profile(model.cuda(), inputs=(input, ))\n",
    "flops, params = clever_format([flops, params], \"%.3f\")\n",
    "print(f\"FLOPS: {flops}, Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_compressed, (1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compressed.eval()\n",
    "# model_compressed = torch.compile(model_compressed)\n",
    "trt_model = torch_tensorrt.compile(model_compressed.cuda(), \n",
    "    inputs= [torch_tensorrt.Input((1, 3, 224, 224))],\n",
    "    truncate_long_and_double = True,\n",
    "    # enabled_precisions= { torch_tensorrt.dtype.half} # Run with FP16\n",
    "    enabled_precisions= { torch.float} # Run with FP16\n",
    ")\n",
    "# trt_ts_module = torch_tensorrt.compile(model, \n",
    "#     inputs= [torch_tensorrt.Input((1, 3, 224, 224))],\n",
    "#     enabled_precisions= { torch.float} # Run with FP16\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/100, avg batch time 63.39 ms\n",
      "Iteration 20/100, avg batch time 59.57 ms\n",
      "Iteration 30/100, avg batch time 58.94 ms\n",
      "Iteration 40/100, avg batch time 57.68 ms\n",
      "Iteration 50/100, avg batch time 57.82 ms\n",
      "Iteration 60/100, avg batch time 59.55 ms\n",
      "Iteration 70/100, avg batch time 59.55 ms\n",
      "Iteration 80/100, avg batch time 59.06 ms\n",
      "Iteration 90/100, avg batch time 57.62 ms\n",
      "Iteration 100/100, avg batch time 58.59 ms\n",
      "Input shape: torch.Size([1, 3, 224, 224])\n",
      "Average throughput: 17.07 images/second\n"
     ]
    }
   ],
   "source": [
    "# benchmark(model_compressed, input_shape=(1, 3, 224, 224), nruns=100)\n",
    "# benchmark(trt_model, input_shape=(1, 3, 224, 224), nruns=100, cuda=True, dtype=\"fp16\")\n",
    "benchmark(trt_model, input_shape=(1, 3, 224, 224), nruns=100, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/deit3_small_patch16_224.fb_in1k)\n",
      "INFO:timm.models._hub:[timm/deit3_small_patch16_224.fb_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    }
   ],
   "source": [
    "model = create_model(model_name=\"deit3_small_patch16_224.fb_in1k\", pretrained=True)\n",
    "# model = model.half()\n",
    "# summary(model, (1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/deit3_small_patch16_224.fb_in1k)\n",
      "INFO:timm.models._hub:[timm/deit3_small_patch16_224.fb_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "FLOPS: 4.249G, Params: 21.975M\n"
     ]
    }
   ],
   "source": [
    "model = create_model(model_name=\"deit3_small_patch16_224.fb_in1k\", pretrained=True)\n",
    "flops, params = profile(model.cuda(), inputs=(input, ))\n",
    "flops, params = clever_format([flops, params], \"%.3f\")\n",
    "print(f\"FLOPS: {flops}, Params: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Unused Input: input_0\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - [RemoveDeadLayers] Input Tensor input_0 is unused or used only at compile-time, but is not being removed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Unused Input: input_0\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - [RemoveDeadLayers] Input Tensor input_0 is unused or used only at compile-time, but is not being removed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Unused Input: input_0\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - [RemoveDeadLayers] Input Tensor input_0 is unused or used only at compile-time, but is not being removed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Unused Input: input_0\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - [RemoveDeadLayers] Input Tensor input_0 is unused or used only at compile-time, but is not being removed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Unused Input: input_0\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - [RemoveDeadLayers] Input Tensor input_0 is unused or used only at compile-time, but is not being removed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Unused Input: input_0\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - [RemoveDeadLayers] Input Tensor input_0 is unused or used only at compile-time, but is not being removed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Unused Input: input_0\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - [RemoveDeadLayers] Input Tensor input_0 is unused or used only at compile-time, but is not being removed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Unused Input: input_0\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - [RemoveDeadLayers] Input Tensor input_0 is unused or used only at compile-time, but is not being removed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Unused Input: input_0\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - [RemoveDeadLayers] Input Tensor input_0 is unused or used only at compile-time, but is not being removed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Unused Input: input_0\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - [RemoveDeadLayers] Input Tensor input_0 is unused or used only at compile-time, but is not being removed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Unused Input: input_0\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - [RemoveDeadLayers] Input Tensor input_0 is unused or used only at compile-time, but is not being removed.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Unused Input: input_0\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - [RemoveDeadLayers] Input Tensor input_0 is unused or used only at compile-time, but is not being removed.\n"
     ]
    }
   ],
   "source": [
    "# model = torch.compile(model)\n",
    "model.eval()\n",
    "trt_model1 = torch_tensorrt.compile(model.cuda(), \n",
    "    inputs= [torch_tensorrt.Input((1, 3, 224, 224))],\n",
    "    truncate_long_and_double = True,\n",
    "    # enabled_precisions= { torch_tensorrt.dtype.half} # Run with FP16\n",
    "    enabled_precisions= { torch.float} # Run with FP16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/100, avg batch time 50.39 ms\n",
      "Iteration 20/100, avg batch time 50.11 ms\n",
      "Iteration 30/100, avg batch time 49.69 ms\n",
      "Iteration 40/100, avg batch time 49.91 ms\n",
      "Iteration 50/100, avg batch time 50.29 ms\n",
      "Iteration 60/100, avg batch time 51.29 ms\n",
      "Iteration 70/100, avg batch time 51.20 ms\n",
      "Iteration 80/100, avg batch time 51.13 ms\n",
      "Iteration 90/100, avg batch time 51.07 ms\n",
      "Iteration 100/100, avg batch time 50.98 ms\n",
      "Input shape: torch.Size([1, 3, 224, 224])\n",
      "Average throughput: 19.61 images/second\n"
     ]
    }
   ],
   "source": [
    "benchmark(model, input_shape=(1, 3, 224, 224), nruns=100)\n",
    "# benchmark(trt_model1, input_shape=(1, 3, 224, 224), nruns=100, cuda=True, dtype=\"fp16\")\n",
    "# benchmark(trt_model1, input_shape=(1, 3, 224, 224), nruns=100, cuda=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
