{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from pytorch_msssim import ssim  # You can install this package for SSIM calculation in PyTorch\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "\n",
    "traindir = os.path.join(\"/work/u1887834/imagenet/\", 'train')\n",
    "imagenet_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "    ]))\n",
    "# dataloader = DataLoader(imagenet_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, sampler=None)\n",
    "\n",
    "# Function to perform SSIM comparison between two batches\n",
    "def compare_batch_to_batch(batch1, batch2, start_idx1, start_idx2, ssim_matrix):\n",
    "    for i, img1 in enumerate(batch1):\n",
    "        for j, img2 in enumerate(batch2):\n",
    "            if start_idx1 + i == start_idx2 + j:  # Skip comparing the image with itself\n",
    "                continue\n",
    "            if start_idx1 + i > start_idx2 + j:  # Avoid duplicate comparisons\n",
    "                continue\n",
    "            score = ssim(img1.unsqueeze(0), img2.unsqueeze(0)).item()\n",
    "            ssim_matrix[start_idx1 + i, start_idx2 + j] = score\n",
    "            ssim_matrix[start_idx2 + j, start_idx1 + i] = score  # Matrix is symmetric\n",
    "\n",
    "second_elements = np.array([x[1] for x in imagenet_dataset.imgs])\n",
    "indices = np.where(second_elements == 0)[0]\n",
    "torch_indices= torch.tensor(indices, dtype=torch.long)\n",
    "first_category_subset = Subset(imagenet_dataset, torch_indices)\n",
    "N = len(first_category_subset)\n",
    "\n",
    "batch_size=50\n",
    "\n",
    "first_category_dataloader = DataLoader(first_category_subset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, sampler=None)\n",
    "\n",
    "# Preload all data into a list\n",
    "all_batches = [batch.cuda() for (batch, _) in first_category_dataloader]\n",
    "\n",
    "ssim_matrix = torch.zeros((N, N))\n",
    "\n",
    "# Function to populate SSIM matrix\n",
    "def perform_comparisons():\n",
    "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        futures = []\n",
    "        for i, batch1 in enumerate(all_batches):\n",
    "            for j, batch2 in enumerate(all_batches):\n",
    "                if i > j:\n",
    "                    continue\n",
    "                future = executor.submit(compare_batch_to_batch, batch1, batch2, i * batch_size, j * batch_size, ssim_matrix)\n",
    "                futures.append(future)\n",
    "\n",
    "        # Wait for all futures to complete\n",
    "        for future in futures:\n",
    "            future.result()\n",
    "\n",
    "# Perform the comparisons\n",
    "perform_comparisons()\n",
    "\n",
    "# Show a small portion of the matrix for illustration\n",
    "ssim_matrix[:5, :5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ssim among all images in one class:   2%|â–Ž         | 10/400 [1:14:24<49:13:35, 454.40s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from pytorch_msssim import ssim  # You can install this package for SSIM calculation in PyTorch\n",
    "from pytorch_msssim import SSIM\n",
    "import os\n",
    "# batch_size = 64\n",
    "traindir = os.path.join(\"/work/u1887834/imagenet/\", 'train')\n",
    "imagenet_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "    ]))\n",
    "# dataloader = DataLoader(imagenet_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, sampler=None)\n",
    "\n",
    "ssim_compiled = torch.compile(SSIM(data_range=1.0, size_average=False))\n",
    "\n",
    "\n",
    "# num = 1\n",
    "\n",
    "\n",
    "second_elements = np.array([x[1] for x in imagenet_dataset.imgs])\n",
    "ssim_matrix_list = []\n",
    "from tqdm import tqdm\n",
    "\n",
    "for classe in tqdm(range(600, 1000), desc=\"ssim among all images in one class\"):\n",
    "    \n",
    "    indices = np.where(second_elements == classe)[0]\n",
    "    torch_indices= torch.tensor(indices, dtype=torch.long)\n",
    "    category_subset = Subset(imagenet_dataset, torch_indices)\n",
    "    N = len(category_subset)\n",
    "    batch_size=N\n",
    "    category_dataloader = DataLoader(category_subset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, sampler=None)\n",
    "\n",
    "    ssim_matrix = torch.zeros((N, N))\n",
    "    \n",
    "    for i, (batch, _) in enumerate(category_dataloader):\n",
    "        batch = batch.cuda()  # Move to GPU\n",
    "        for x in range(len(batch)):\n",
    "            for y in range(x + 1, len(batch)):  # Skip redundant comparisons\n",
    "                # print(x, y)\n",
    "                img1 = batch[x].unsqueeze(0)  # Convert to 4D tensor (NCHW)\n",
    "                img2 = batch[y].unsqueeze(0)  # Convert to 4D tensor (NCHW)\n",
    "\n",
    "                ssim_value = ssim_compiled(img1, img2)\n",
    "\n",
    "                # Populate the SSIM matrix; calculate the absolute index based on batch and position within batch\n",
    "                ssim_matrix[x, y] = ssim_value\n",
    "                ssim_matrix[y, x] = ssim_value  # SSIM is symmetric\n",
    "    del category_dataloader\n",
    "    # Move ssim_matrix back to CPU if needed\n",
    "    ssim_matrix = ssim_matrix.cpu()\n",
    "    torch.save(ssim_matrix, f'/home/u1887834/Research/data/ssim_matrix_{classe}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ssim_matrix_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ssim_matrix_list, './data/ssim_matrix_list_100_126.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.2224, 0.1475,  ..., 0.2355, 0.1468, 0.1239],\n",
       "        [0.2224, 0.0000, 0.1813,  ..., 0.4116, 0.2524, 0.2100],\n",
       "        [0.1475, 0.1813, 0.0000,  ..., 0.2146, 0.1287, 0.1181],\n",
       "        ...,\n",
       "        [0.2355, 0.4116, 0.2146,  ..., 0.0000, 0.2676, 0.2283],\n",
       "        [0.1468, 0.2524, 0.1287,  ..., 0.2676, 0.0000, 0.1266],\n",
       "        [0.1239, 0.2100, 0.1181,  ..., 0.2283, 0.1266, 0.0000]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssim_matrix0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
